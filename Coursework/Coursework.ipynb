{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Cq5p0Tdc5zGG",
        "p5Bsa6SAjCmn",
        "1flTS8wbirS-",
        "Kd0J0i2xwit0",
        "_eU3BnDwXXop",
        "pD7g96wTS7DT",
        "qK2VtRwxBnM1",
        "3ew1h6pDTtES",
        "MTRuyw7LQaxE",
        "QZXQDBv1wtFW",
        "hElmknMx1gyM",
        "HoyNde0dLpZF",
        "kmNIAQZZbstb",
        "3xtl5FGVck7s",
        "VdwSUfSnbupF"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAmA1Tr1ybJK"
      },
      "source": [
        "# **<center>Machine Learning and Finance </center>**\n",
        "\n",
        "\n",
        "## <center> Coursework </center>\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"center\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://hm-ai.github.io/MLF/\">\n",
        "    <img src=\"https://drive.google.com/uc?export=view&id=1gmxxmwCR1WXK0IYtNqvE4QXFleznWqQO\" height=\"50\"/>\n",
        "    Course page</a>\n",
        "</td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/drive/1-bWh9KsN0f7ZlgVKzrtvqHmcAYCKTSeK?usp=sharing\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" height=\"50\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "</table>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**Contact**\n",
        "\n",
        "If you have any questions regarding this notebook, please do not hesitate to contact me at: h.madmoun@imperial.ac.uk\n",
        "\n",
        "---\n",
        "---\n",
        "**Instructions:**\n",
        "\n",
        "* The code should be presented as a python file or a jupyter notebook.\n",
        "\n",
        "* The theoretical questions can be answered in the jupyter notebook or in a separate pdf.\n",
        "\n",
        "\n",
        "---\n",
        "---\n",
        "**Presentation of the Coursework:**\n",
        "\n",
        "In this coursework, we would like to introduce an interpretable Neural Network to handle the same classification problem introduced in [Programming Session 3](https://colab.research.google.com/drive/1UZDULRgUxqbkjSo-ZGJn15_URwRQDKVX?usp=sharing). \n",
        "\n",
        "\n",
        "The coursework is structured into three sections:\n",
        "\n",
        "* In Section 1, we undertake data preprocessing, which involves scaling the numerical features and applying Label Encoding to the categorical features.\n",
        "* In Section 2, we develop and train a model, as depicted in the following diagram:\n",
        "<center><img width=\"1000\" src = \"https://drive.google.com/uc?export=view&id=1Aj7nc0QSS5hweGx_xPUbYH-5L6_2HRgz\"></center>\n",
        "* In Section 3, we adapt the model presented in Section 2 to address a sequential problem.\n",
        "\n",
        "\n",
        "---\n",
        "The coursework is graded out of 100. The following table presents the details of the grading scale used.\n",
        "\n",
        "| Question | Number of Marks |\n",
        "|----------|-----------------|\n",
        "| Q1       | 3 marks         |\n",
        "| Q2       | 3 marks         |\n",
        "| Q3       | 3 marks         |\n",
        "| Q4       | 3 marks         |\n",
        "| Q5       | 3 marks         |\n",
        "| Q6       | 3 marks         |\n",
        "| Q7       | 3 marks         |\n",
        "| Q8       | 6 marks         |\n",
        "| Q9       | 3 marks         |\n",
        "| Q10      | 3 marks         |\n",
        "| Q11      | 3 marks         |\n",
        "| Q12      | 3 marks         |\n",
        "| Q13      | 3 marks         |\n",
        "| Q14      | 3 marks         |\n",
        "| Q15      | 3 marks         |\n",
        "| Q16      | 3 marks         |\n",
        "| Q17      | 3 marks         |\n",
        "| Q18      | 3 marks         |\n",
        "| Q19      | 4 marks         |\n",
        "| Q20      | 3 marks         |\n",
        "| Q21      | 4 marks         |\n",
        "| Q22      | 3 marks         |\n",
        "| Q23      | 4 marks         |\n",
        "| Q24      | 4 marks         |\n",
        "| Q25      | 4 marks         |\n",
        "| Q26      | 4 marks         |\n",
        "| Q27      | 3 marks         |\n",
        "| Q28      | 10 marks        |\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "8tiUNZK3r53F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing the Data"
      ],
      "metadata": {
        "id": "81kUcaVEcLV9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load the Data"
      ],
      "metadata": {
        "id": "Cq5p0Tdc5zGG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd # for dataframes\n",
        "import matplotlib.pyplot as plt # as usual for plots\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Layer, Input, Dense, Concatenate, Embedding, LayerNormalization, Dropout\n",
        "from tensorflow.keras.metrics import AUC, Precision, Recall"
      ],
      "metadata": {
        "id": "x_oge2jy5MC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Access files from Google Drive\n",
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eO42elat5ctS",
        "outputId": "5de08830-3b6d-45ba-973b-5f925f3df085"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the path to your working directory\n",
        "os.chdir(\"./gdrive/My Drive/Teaching/Imperial_College/Coursework/\")"
      ],
      "metadata": {
        "id": "9UnXvfxq5M2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "<font color=green>Q1:</font>\n",
        "<br><font color='green'>\n",
        "The data is stored in the folder \"data\". Load the dataframe and shuffle the rows, then display 5 random rows in the dataframe.\n",
        "</font>\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "aXeXv79FWk_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Import data\n"
      ],
      "metadata": {
        "id": "DIjN41OnZGSF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Shuffle the rows\n"
      ],
      "metadata": {
        "id": "d5dqKPecZHZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Sample 5 random rows\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "OCOVEDWtZHoC",
        "outputId": "8c721c11-68d4-44a3-e583-fe08ee09acec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       person_age  person_income person_home_ownership  person_emp_length  \\\n",
              "32050          25         103000              MORTGAGE                4.0   \n",
              "8264           39          91992              MORTGAGE                0.0   \n",
              "14937          22          55000                  RENT                5.0   \n",
              "1846           22          60612              MORTGAGE                6.0   \n",
              "3076           22          68500              MORTGAGE                3.0   \n",
              "\n",
              "             loan_intent loan_grade  loan_amnt  loan_int_rate  loan_status  \\\n",
              "32050           PERSONAL          A      29175          10.99            0   \n",
              "8264     HOMEIMPROVEMENT          A       3350           5.42            0   \n",
              "14937  DEBTCONSOLIDATION          A       6000           7.51            0   \n",
              "1846            PERSONAL          B       5300          10.99            0   \n",
              "3076            PERSONAL          B      12000          10.99            0   \n",
              "\n",
              "       loan_percent_income cb_person_default_on_file  \\\n",
              "32050                 0.28                         N   \n",
              "8264                  0.04                         N   \n",
              "14937                 0.11                         N   \n",
              "1846                  0.09                         N   \n",
              "3076                  0.18                         N   \n",
              "\n",
              "       cb_person_cred_hist_length  \n",
              "32050                           2  \n",
              "8264                           11  \n",
              "14937                           3  \n",
              "1846                            4  \n",
              "3076                            4  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7bee72e7-db0b-4b45-9c0a-5c110350c5e6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>person_age</th>\n",
              "      <th>person_income</th>\n",
              "      <th>person_home_ownership</th>\n",
              "      <th>person_emp_length</th>\n",
              "      <th>loan_intent</th>\n",
              "      <th>loan_grade</th>\n",
              "      <th>loan_amnt</th>\n",
              "      <th>loan_int_rate</th>\n",
              "      <th>loan_status</th>\n",
              "      <th>loan_percent_income</th>\n",
              "      <th>cb_person_default_on_file</th>\n",
              "      <th>cb_person_cred_hist_length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>32050</th>\n",
              "      <td>25</td>\n",
              "      <td>103000</td>\n",
              "      <td>MORTGAGE</td>\n",
              "      <td>4.0</td>\n",
              "      <td>PERSONAL</td>\n",
              "      <td>A</td>\n",
              "      <td>29175</td>\n",
              "      <td>10.99</td>\n",
              "      <td>0</td>\n",
              "      <td>0.28</td>\n",
              "      <td>N</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8264</th>\n",
              "      <td>39</td>\n",
              "      <td>91992</td>\n",
              "      <td>MORTGAGE</td>\n",
              "      <td>0.0</td>\n",
              "      <td>HOMEIMPROVEMENT</td>\n",
              "      <td>A</td>\n",
              "      <td>3350</td>\n",
              "      <td>5.42</td>\n",
              "      <td>0</td>\n",
              "      <td>0.04</td>\n",
              "      <td>N</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14937</th>\n",
              "      <td>22</td>\n",
              "      <td>55000</td>\n",
              "      <td>RENT</td>\n",
              "      <td>5.0</td>\n",
              "      <td>DEBTCONSOLIDATION</td>\n",
              "      <td>A</td>\n",
              "      <td>6000</td>\n",
              "      <td>7.51</td>\n",
              "      <td>0</td>\n",
              "      <td>0.11</td>\n",
              "      <td>N</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1846</th>\n",
              "      <td>22</td>\n",
              "      <td>60612</td>\n",
              "      <td>MORTGAGE</td>\n",
              "      <td>6.0</td>\n",
              "      <td>PERSONAL</td>\n",
              "      <td>B</td>\n",
              "      <td>5300</td>\n",
              "      <td>10.99</td>\n",
              "      <td>0</td>\n",
              "      <td>0.09</td>\n",
              "      <td>N</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3076</th>\n",
              "      <td>22</td>\n",
              "      <td>68500</td>\n",
              "      <td>MORTGAGE</td>\n",
              "      <td>3.0</td>\n",
              "      <td>PERSONAL</td>\n",
              "      <td>B</td>\n",
              "      <td>12000</td>\n",
              "      <td>10.99</td>\n",
              "      <td>0</td>\n",
              "      <td>0.18</td>\n",
              "      <td>N</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7bee72e7-db0b-4b45-9c0a-5c110350c5e6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7bee72e7-db0b-4b45-9c0a-5c110350c5e6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7bee72e7-db0b-4b45-9c0a-5c110350c5e6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data used in this coursework is the one we have used in Programming Session 3. In this dataset, each entry represents a person who takes a credit by a bank. "
      ],
      "metadata": {
        "id": "_gPqz3TJVvqj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The target is: `loan_status`. It takes two possible values:\n",
        "\n",
        "\n",
        "* 1 in case of default.\n",
        "* 0 otherwise.\n",
        "\n"
      ],
      "metadata": {
        "id": "1wAu3-W5W7fN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "<font color=green>Q2:</font>\n",
        "<br><font color='green'>\n",
        "Show that it is a binary classification problem and that the dataset is highly imbalanced.\n",
        "</font>\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "JviraydcXGx2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Show it's a Binary Classification Problem\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AeweMdjXW7DF",
        "outputId": "f396c544-059d-406f-d775-17de962e4384"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "xxRF_SU2WkC8",
        "outputId": "9557f35f-8525-4c9c-d0db-85c4ad1449f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adding a categorical variable"
      ],
      "metadata": {
        "id": "p5Bsa6SAjCmn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "<font color=green>Q3:</font>\n",
        "<br><font color='green'>\n",
        "Describe the way we created the categorical variable `category_income` in [Programming Session 3](https://colab.research.google.com/drive/1UZDULRgUxqbkjSo-ZGJn15_URwRQDKVX?usp=sharing).\n",
        "Create the cateorical variable `category_income`. \n",
        "</font>\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "v5Q6q3SVZvQg"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tDw2ugxMgDd9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "<font color=green>Q4:</font>\n",
        "<br><font color='green'>\n",
        "Print the number of categories associated with the categorical variable `loan_grade` and print the different categories.\n",
        "</font>\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "B3HaTKxKhPre"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81D-GUyghlvZ",
        "outputId": "85e5a444-6d2d-464a-9a43-962f3365d09b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The categorical variable loan_grade contains 7 categories\n",
            "The different categories of the categorical variable loan_grade are:  ['B' 'A' 'C' 'D' 'E' 'F' 'G']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "<font color=green>Q5:</font>\n",
        "<br><font color='green'>\n",
        "Create a list called `catvars` containing the 5 categorical variables.\n",
        "Create a list called `cardinalities` containing the number of categories associated with each categorical variable in `catvars`.\n",
        "</font>\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "U4Bixb49gqw-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyV047tdgZDr",
        "outputId": "a59e8c4f-5ae5-4d47-944d-54091c8cff8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The list categories contains the following elements:  ['person_home_ownership', 'loan_intent', 'loan_grade', 'cb_person_default_on_file', 'category_income']\n",
            "The list cardinalities contains the following elements:  [4, 6, 7, 2, 4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following table shows the different categories for each categorical variable. "
      ],
      "metadata": {
        "id": "8U81wWA1a6L2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Categorical Variable      | Categories                                                                                        |\n",
        "|---------------------------|---------------------------------------------------------------------------------------------------|\n",
        "| person_home_ownership     | ['MORTGAGE', 'RENT', 'OWN', 'OTHER']                                                              |\n",
        "| loan_intent               | ['DEBTCONSOLIDATION',   'PERSONAL',   'VENTURE',   'EDUCATION',   'MEDICAL',   'HOMEIMPROVEMENT'] |\n",
        "| loan_grade                | ['A', 'C', 'B', 'E', 'D', 'G', 'F']                                                               |\n",
        "| cb_person_default_on_file | ['N', 'Y']                                                                                        |\n",
        "| category_income           | ['B', 'D', 'C', 'A']                                                                              |"
      ],
      "metadata": {
        "id": "o0XM1aE0VCYW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "<font color=green>Q6:</font>\n",
        "<br><font color='green'>\n",
        "Create a list called `numvars` containing the 7 numerical variables. Describe their distributions.\n",
        "</font>\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "YR9fhmXvjlR2"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpTOIRG3j77k",
        "outputId": "a1fedea3-5ead-43ea-93b4-ecc97cddf7ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The numerical variables are:  ['person_age', 'person_income', 'person_emp_length', 'loan_amnt', 'loan_int_rate', 'loan_percent_income', 'cb_person_cred_hist_length']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Description of the numerical variables distribution\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "hy0hok4EkUIy",
        "outputId": "835b0f18-9913-4bf6-852a-1ff34eac0175"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         person_age  person_income  person_emp_length     loan_amnt  \\\n",
              "count  32581.000000   3.258100e+04       32581.000000  32581.000000   \n",
              "mean      27.734600   6.607485e+04           4.767994   9589.371106   \n",
              "std        6.348078   6.198312e+04           4.087372   6322.086646   \n",
              "min       20.000000   4.000000e+03           0.000000    500.000000   \n",
              "25%       23.000000   3.850000e+04           2.000000   5000.000000   \n",
              "50%       26.000000   5.500000e+04           4.000000   8000.000000   \n",
              "75%       30.000000   7.920000e+04           7.000000  12200.000000   \n",
              "max      144.000000   6.000000e+06         123.000000  35000.000000   \n",
              "\n",
              "       loan_int_rate  loan_percent_income  cb_person_cred_hist_length  \n",
              "count   32581.000000         32581.000000                32581.000000  \n",
              "mean       11.009620             0.170203                    5.804211  \n",
              "std         3.081611             0.106782                    4.055001  \n",
              "min         5.420000             0.000000                    2.000000  \n",
              "25%         8.490000             0.090000                    3.000000  \n",
              "50%        10.990000             0.150000                    4.000000  \n",
              "75%        13.110000             0.230000                    8.000000  \n",
              "max        23.220000             0.830000                   30.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9dc596d7-3602-49c3-bd39-294213372fba\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>person_age</th>\n",
              "      <th>person_income</th>\n",
              "      <th>person_emp_length</th>\n",
              "      <th>loan_amnt</th>\n",
              "      <th>loan_int_rate</th>\n",
              "      <th>loan_percent_income</th>\n",
              "      <th>cb_person_cred_hist_length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>32581.000000</td>\n",
              "      <td>3.258100e+04</td>\n",
              "      <td>32581.000000</td>\n",
              "      <td>32581.000000</td>\n",
              "      <td>32581.000000</td>\n",
              "      <td>32581.000000</td>\n",
              "      <td>32581.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>27.734600</td>\n",
              "      <td>6.607485e+04</td>\n",
              "      <td>4.767994</td>\n",
              "      <td>9589.371106</td>\n",
              "      <td>11.009620</td>\n",
              "      <td>0.170203</td>\n",
              "      <td>5.804211</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>6.348078</td>\n",
              "      <td>6.198312e+04</td>\n",
              "      <td>4.087372</td>\n",
              "      <td>6322.086646</td>\n",
              "      <td>3.081611</td>\n",
              "      <td>0.106782</td>\n",
              "      <td>4.055001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>20.000000</td>\n",
              "      <td>4.000000e+03</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>500.000000</td>\n",
              "      <td>5.420000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>23.000000</td>\n",
              "      <td>3.850000e+04</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>5000.000000</td>\n",
              "      <td>8.490000</td>\n",
              "      <td>0.090000</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>26.000000</td>\n",
              "      <td>5.500000e+04</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>8000.000000</td>\n",
              "      <td>10.990000</td>\n",
              "      <td>0.150000</td>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>30.000000</td>\n",
              "      <td>7.920000e+04</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>12200.000000</td>\n",
              "      <td>13.110000</td>\n",
              "      <td>0.230000</td>\n",
              "      <td>8.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>144.000000</td>\n",
              "      <td>6.000000e+06</td>\n",
              "      <td>123.000000</td>\n",
              "      <td>35000.000000</td>\n",
              "      <td>23.220000</td>\n",
              "      <td>0.830000</td>\n",
              "      <td>30.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9dc596d7-3602-49c3-bd39-294213372fba')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9dc596d7-3602-49c3-bd39-294213372fba button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9dc596d7-3602-49c3-bd39-294213372fba');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing numerical and categorical variables"
      ],
      "metadata": {
        "id": "1flTS8wbirS-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll begin by dividing the dataset into a training set and a test set. The training set will contain 70% of the data and will be used to train our model. The remaining 30% will form the test set and will be used to evaluate the performance of the model.\n",
        "\n",
        "When dealing with categorical variables, it's important to remember that machine learning models are mathematical models and work with numbers. Therefore, these categories must be transformed into numbers before we can use them to fit and validate a model.\n",
        "\n",
        "Consider a simple example where we have a categorical variable with three unique values: 'A', 'B', and 'C'.\n",
        "\n",
        "Label Encoding would involve assigning each unique category value a unique integer. We could assign 'A' to '0', 'B' to '1', and 'C' to '2'. After encoding, our data will look like this:\n",
        "\n",
        "| categorical_variable | Index  |\n",
        "|-------|-------|\n",
        "| A     | 0   |\n",
        "| B     | 1   |\n",
        "| C     | 2   |\n",
        "\n",
        "This way, we have transformed our categorical data into numerical data, which makes it compatible for a machine learning algorithm.\n",
        "\n",
        "In addition to this, machine learning algorithms perform better when input numerical variables fall within a similar scale. Therefore, we'll scale (normalize) our numerical variables so they all have a similar range of values. \n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TnjaLPADmQK9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "<font color=green>Q7:</font>\n",
        "<br><font color='green'>\n",
        "Describe two methods to scale the numerical variables. \n",
        "</font>\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "145kreYTrd0G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "<font color=green>Q8:</font>\n",
        "<br><font color='green'>\n",
        "Split the dataset into training and test sets. \n",
        "Process all the categorical variables using Label Encoding. \n",
        "Scale the numerical variables using your preferred method.\n",
        "Extract the training and test targets.\n",
        "</font>\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "peDyoqN7reXP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following table summarizes the tensors you should create:\n",
        "\n",
        "| Description of the Tensor                                                                                                       | Name        | Shape        |\n",
        "|---------------------------------------------------------------------------------------------------------------------------------|-------------|--------------|\n",
        "| The tensor containing all the numerical features associated with the training dataset                                           | X_num_train | $(N_T, D_n)$ |\n",
        "| The tensor containing all the label encoded categorical features associated with the training dataset                           | X_cat_train | $(N_T, D_c)$ |\n",
        "| The tensor containing all the features (numerical and label encoded categorical features) associated with the training dataset  | X_train     | $(N_T, D)$   |\n",
        "| The tensor containing all the numerical features associated with the test dataset                                               | X_num_test  | $(N_t, D_n)$ |\n",
        "| The tensor containing all the label encoded categorical features associated with the test dataset                               | X_cat_test  | $(N_t, D_c)$ |\n",
        "| The tensor containing all the features (numerical and label encoded categorical features) associated with the test dataset      | X_test      | $(N_t, D)$   |\n",
        "| The training target tensor                                                                                                      | y_train     | $(N_T,)$   |\n",
        "| The test target tensor                                                                                                          | y_test      | $(N_t,)$   |\n",
        "\n"
      ],
      "metadata": {
        "id": "ZLrioDXtz0q9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "where:\n",
        "\n",
        "|                  | Notation |\n",
        "|--------------------------------|----------|\n",
        "| Number of Training Data        | $N_T$    |\n",
        "| Number of Test Data            | $N_t$    |\n",
        "| Number of numerical features   | $D_n$    |\n",
        "| Number of categorical features | $D_c$    |\n",
        "| Number of all features         | $D       |\n"
      ],
      "metadata": {
        "id": "mt6cgjbeW5eQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Prediction Model"
      ],
      "metadata": {
        "id": "3Z9whjHWS1Zk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Processing the Data"
      ],
      "metadata": {
        "id": "Kd0J0i2xwit0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Introduction"
      ],
      "metadata": {
        "id": "_eU3BnDwXXop"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We denote $x_i \\in \\mathbb{R}^D$ the D-dimensional vector representing all the processed features:\n",
        "\n",
        "* The first $D_n$ dimensions are the numerical variables. \n",
        "* The last $D_c$ dimensions are the label encoded categorical variables. \n",
        "\n",
        "\n",
        "<center><img width=\"400\" src = \"https://drive.google.com/uc?export=view&id=1haI7b3oi60irjOv7W9iES99aUN1gPOMJ\"></center>\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1uwCEGw18bk0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Therefore, the first $D_n$ indices $d \\in \\{1, \\dots, D_n\\}$ are associated with the numerical variables $x_i^d$. \n",
        "\n",
        "Each categorical variable $x_i^{d'}$ of index $d'$ (where $d' \\in \\{D_n +1, \\dots, D_n + D_c \\}$) has $n_{d'}$ possible categories, as summarized in the following table:\n",
        "\n",
        "| Categorical Variables      | Cardinalities                                                                                        |\n",
        "|---------------------------|---------------------------------------------------------------------------------------------------|\n",
        "| person_home_ownership     | 4                                                              |\n",
        "| loan_intent               | 6 |\n",
        "| loan_grade                | 7                                                             |\n",
        "| cb_person_default_on_file | 2                                                                                    |\n",
        "| category_income           | 4                                                      |"
      ],
      "metadata": {
        "id": "McL-K8AYAh57"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Encoding the numerical and the categorical variables into $D_e$-dimensional vectors"
      ],
      "metadata": {
        "id": "pD7g96wTS7DT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "<font color=green>Q9:</font>\n",
        "<br><font color='green'>\n",
        "What is the primary limitation of Label Encoding and how was this circumvented during Programming Session 3?\n",
        "</font>\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "6H91f7TjqKsJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let $D_e$ be the size of the embedding space. We would like to encode each feature (numerical or categorical) into a $D_e$-dimensional vector. To that end, we will use: \n",
        "\n",
        "* **Dense Layers** for numerical features. \n",
        "\n",
        "  Therefore, the numerical feature $x_i^d$ (for $d \\in \\{1, \\dots, D_n\\}$) will be mapped into a $D_e$-dimensional vector $\\xi_i^d \\in \\mathbb{R}^{D_e}$.\n",
        "\n",
        "\n",
        "* **Embedding Layers** for categorical features. \n",
        "\n",
        "  The idea is to represent each category as a vector in a continuous vector space, rather than using one-hot encoding or Label Encoding. This has the advantage of capturing more complex relationships between categories, which can be especially important when dealing with categorical variables that have many categories. Therefore, the categorical feature $x_i^{d'}$ (for $d' \\in \\{D_n + 1, \\dots, D_n + D_c\\}$) will be mapped into a $D_e$-dimensional vector $\\xi_i^{d'} \\in \\mathbb{R}^{D_e}$."
      ],
      "metadata": {
        "id": "lIOUMZbZACP3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Example: Exploring one of the categorical variables `loan_grade`"
      ],
      "metadata": {
        "id": "qK2VtRwxBnM1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Suppose $d'$ is the index of the categorical variable `load_grade`, which has $n_{d'} = 7$ possible values, encoded into $\\{0, 1, \\dots, 6\\}$ using Label Encoding.\n",
        "\n",
        "Suppose we create an embedding layer (with the corresponding embedding_matrix $\\mathcal{E}_{d'}$) to process the categorical variable `load_grade`. \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "oY3difyn_2Vn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "<font color=green>Q10:</font>\n",
        "<br><font color='green'>\n",
        "Explain why the embedding matrix $\\mathcal{E}_{d'}$ associated with the categorical variable `loan_grade` is of shape $(n_{d'}, D_e$)\n",
        "\n",
        "</font>\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "FlN3SbOEPgR6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These embedding vectors are learned during the training process and are updated via backpropagation, just like any other weights in the network"
      ],
      "metadata": {
        "id": "7tMN07CgQS7N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "<font color=green>Q11:</font>\n",
        "<br><font color='green'>\n",
        "What would be the embedding vector associated with the category 2 of `loan_grade`?\n",
        "\n",
        "</font>\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "MVFPeL10YDWF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Introducing the `InputTransformation` Layer"
      ],
      "metadata": {
        "id": "3ew1h6pDTtES"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following custom TensorFlow layer, named `InputTransformation`, is designed to process numerical and categorical features as described previously.\n",
        "\n",
        "This layer takes as input the numerical tensor `X_num_train` $\\in \\mathbb{R}^{N_T \\times D_n}$ and the categorical tensor `X_cat_train` $\\in \\mathbb{R}^{N_T \\times D_c}$ and transforms them into a more representative space (embedded space) which can be further processed by downstream layers.\n",
        "\n",
        "\n",
        "The `InputTransformation` class has several key attributes: \n",
        "\n",
        "| Attribute  | Notation      | Description                                                              |\n",
        "|-----------------|---------------|--------------------------------------------------------------------------|\n",
        "| embedding_dim   |$D_e$ | Dimension of the space to which the input features will be mapped.             |                                                  \n",
        "| num_numerical   | $D_n$           | Number of numerical features                                             |\n",
        "| num_categorical | $D_c$           | Number of categorical features                                           |\n",
        "| cardinalities   | cardinalities | List that contains the number of unique values (categories) for each categorical variable. |\n",
        "\n",
        "\n",
        "\n",
        "In the `call` method, the class processes the numerical and categorical features separately. \n",
        "\n",
        "* For each numerical feature, it applies a **Dense layer** (a linear operation with learnable weights and biases), which projects the numerical feature into the embedding space. \n",
        "  \n",
        "  Therefore, the numerical tensor  $\\begin{bmatrix}\n",
        "x_i^1 \\\\\n",
        "\\vdots\\\\\n",
        "x_i^{D_n}\\\\\n",
        "\\end{bmatrix} \\in \\mathbb{R}^{D_n}$ is mapped into the list of tensors $\\left[\\xi_i^1 \\in \\mathbb{R}^{D_e}, \\dots, \\xi_i^d \\in \\mathbb{R}^{D_e}, \\dots, \\xi_i^{D_n} \\in \\mathbb{R}^{D_e} \\right]$\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "* For each categorical feature, it applies an **Embedding layer**, which assigns each category an embedding vector in the embedding space.\n",
        "\n",
        "  Therefore, the categorical tensor  $\\begin{bmatrix}\n",
        "x_i^{D_n+1} \\\\\n",
        "\\vdots\\\\\n",
        "x_i^{D_n + D_c}\\\\\n",
        "\\end{bmatrix} \\in \\mathbb{R}^{D_c}$ is mapped into the list of tensors $\\left[\\xi_i^{D_n +1} \\in \\mathbb{R}^{D_e}, \\dots, \\xi_i^{d'} \\in \\mathbb{R}^{D_e}, \\dots, \\xi_i^{D_n + D_c} \\in \\mathbb{R}^{D_e} \\right]$\n",
        "\n",
        "* The following graph summarizes these transformations: \n",
        "\n",
        "<center><img width=\"700\" src = \"https://drive.google.com/uc?export=view&id=1XGcCfnBVTvOR64kKWWQLMyOyg1CUfdTy\"></center>\n",
        "\n",
        "\n",
        "* Finally, it stacks all the embedded numerical features $\\left[\\xi_i^1 \\in \\mathbb{R}^{D_e}, \\dots, \\xi_i^d \\in \\mathbb{R}^{D_e}, \\dots, \\xi_i^{D_n} \\in \\mathbb{R}^{D_e} \\right]$ and the embeded categorical features $\\left[\\xi_i^{D_n +1} \\in \\mathbb{R}^{D_e}, \\dots, \\xi_i^{d'} \\in \\mathbb{R}^{D_e}, \\dots, \\xi_i^{D_n + D_c} \\in \\mathbb{R}^{D_e} \\right]$ along the last axis, resulting in the tensor $\\left[\\xi_i^1 \\in \\mathbb{R}^{D_e}, \\dots, \\xi_i^d \\in \\mathbb{R}^{D_e}, \\dots, \\xi_i^{D_n} \\in \\mathbb{R}^{D_e}, \\xi_i^{D_n +1} \\in \\mathbb{R}^{D_e}, \\dots, \\xi_i^{d'} \\in \\mathbb{R}^{D_e}, \\dots, \\xi_i^{D_n + D_c} \\in \\mathbb{R}^{D_e} \\right] \\in \\mathbb{R}^{D_e \\times (D_n + D_c)}$ as shown in the following graph: \n",
        "\n",
        "<center><img width=\"700\" src = \"https://drive.google.com/uc?export=view&id=1L-VOZBERHSgGLcc44pcYoCnbl7SIKkwa\"></center>\n",
        "\n"
      ],
      "metadata": {
        "id": "3m2yikIiT5MS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class InputTransformation(tf.keras.layers.Layer):\n",
        "  def __init__(self, embedding_dim, num_numerical, num_categorical, cardinalities, **kwargs):\n",
        "    super(InputTransformation, self).__init__(**kwargs)\n",
        "    # Define the Hyperparameters\n",
        "    self.embedding_dim = embedding_dim\n",
        "    self.num_numerical = num_numerical\n",
        "    self.num_categorical = num_categorical\n",
        "    self.cardinalities = cardinalities\n",
        "\n",
        "    # List of projections\n",
        "    self.list_projection_layers = [Dense(self.embedding_dim) for _ in range(self.num_numerical)]\n",
        "    # List of embedding layers\n",
        "    self.list_embedding_layers = [Embedding(input_dim=cardinality, output_dim=self.embedding_dim)\n",
        "                            for cardinality in self.cardinalities]\n",
        "\n",
        "  def call(self, x_num, x_cat):\n",
        "    \"\"\"\n",
        "    x_num (batch_size, num_numerical)\n",
        "    x_cat (batch_size, num_categorical)\n",
        "    \"\"\"\n",
        "    list_numerical_features = [] # list of num_numerical tensors[(batch_size, embedding_dim),...,(batch_size, embedding_dim)]\n",
        "    # Apply the projections on each feature x_num[:, i:i+1]\n",
        "    for i, projection in enumerate(self.list_projection_layers):\n",
        "      list_numerical_features.append(projection(x_num[:, i:i+1]))\n",
        "    list_categorical_features = [] # list of num_categorical tensors[(batch_size, embedding_dim),...,(batch_size, embedding_dim)]\n",
        "    # Apply the Embedding layers on each categorical feature x_cat[:, i:i+1]\n",
        "    for i, embedding_layer in enumerate(self.list_embedding_layers):\n",
        "      list_categorical_features.append(embedding_layer(x_cat[:, i]))\n",
        "    # stack all the embedding vectors (batch_size, embedding_dim, num_numerical + num_categorical)\n",
        "    stack_features = tf.stack(list_numerical_features + list_categorical_features, axis=-1)\n",
        "    return stack_features"
      ],
      "metadata": {
        "id": "2Y9REiU6SXMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "<font color=green>Q12:</font>\n",
        "<br><font color='green'>\n",
        "Apply the layer on `X_num_train` and `X_cat_train` as follows by filling the following code with the appropriate values:\n",
        "</font>\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "KN5lJlJ_pl_p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of the InputTransformation\n",
        "input_transformation = InputTransformation(\n",
        "  embedding_dim = ### YOUR CODE HERE ###,\n",
        "  num_numerical = ### YOUR CODE HERE ###, \n",
        "  num_categorical = ### YOUR CODE HERE ###, \n",
        "  cardinalities = ### YOUR CODE HERE ###\n",
        ") \n",
        "# Apply it on the tensors X_num_train and X_cat_train as follows:\n",
        "stack_features = input_transformation(X_num_train, X_cat_train)\n",
        "\n",
        "# Print the shape of stack_features\n",
        "### YOUR CODE HERE ###"
      ],
      "metadata": {
        "id": "TfaoQvoxt4zH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "<font color=green>Q13:</font>\n",
        "<br><font color='green'>\n",
        "Explain the shape of `stack_features`\n",
        "</font>\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "zBJ4r6awuCau"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Gated Residual Network"
      ],
      "metadata": {
        "id": "MTRuyw7LQaxE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The Gated Linear Unit Layer\n",
        "\n"
      ],
      "metadata": {
        "id": "QZXQDBv1wtFW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following custom `GatedLinearUnits` (GLU) layer is a special kind of layer introduced in the paper [Language Modeling with Gated Convolutional Networks](https://arxiv.org/pdf/1612.08083.pdf). In general, the purpose of gating mechanisms is to control the flow of information in a neural network, and the Gated Linear Units follow this principle.\n",
        "\n",
        "Here's how this custom TensorFlow layer works:\n",
        "\n",
        "* The `GatedLinearUnits` class has the following attribute: \n",
        "\n",
        "| Attribute  | Notation      | Description                                                              |\n",
        "|-----------------|---------------|--------------------------------------------------------------------------|\n",
        "| output_dim   | d_o             |   Dimension of the output vector                                               |\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "* **Initialization**: When the layer is instantiated, it takes an `output_dim` parameter, which defines the dimensionality of the output space of the layer. \n",
        "\n",
        "* Two dense (fully connected) layers are also initialized: `dense_filter` and `dense_vector`. The `dense_filter` layer uses a **sigmoid** activation function, which will output values between 0 and 1, while `dense_vector` has no activation function specified, meaning it will use a linear activation function by default.\n",
        "\n",
        "* In the `call` method, the input $\\eta \\in \\mathbb{R}^{d_i}$ is processed by both `dense_filter` and `dense_vector`. \n",
        "\n",
        "  * The input vector $\\eta \\in \\mathbb{R}^{d_i}$ is processed by the `dense_filter` layer to get $\\sigma \\left( W_f^T \\eta + b_f \\right) \\in \\mathbb{R}^{d_o}$.\n",
        "  \n",
        "  * The input vector $\\eta \\in \\mathbb{R}^{d_i}$ is also processed by the `dense_vector` layer to get $W^T \\eta + b\\in \\mathbb{R}^{d_o}\n",
        "$.\n",
        "  * The output is the Hadamard product between both output vectors: $\\sigma \\left( W_f^T \\eta + b_f \\right) \\circ \\left(W^T \\eta + b\\right) \\in \\mathbb{R}^{d_o} $.\n",
        "\n",
        "* The `GatedLinearUnit` layer is represented in the following graph: \n",
        "\n",
        "<center><img width=\"900\" src = \"https://drive.google.com/uc?export=view&id=11h7MJpm8t9z7IT03QWbUgAiE53CVzJzd\"></center>\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_089PsGovdJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GatedLinearUnits(tf.keras.layers.Layer):\n",
        "  def __init__(self, output_dim, **kwargs):\n",
        "    super(GatedLinearUnits, self).__init__(**kwargs)\n",
        "    self.output_dim = output_dim\n",
        "    self.dense_filter = Dense(output_dim, activation='sigmoid')\n",
        "    self.dense_vector = Dense(output_dim)\n",
        "  def call(self, x):\n",
        "    filter = self.dense_filter(x)\n",
        "    vector = self.dense_vector(x)\n",
        "    output = tf.multiply(filter, vector)\n",
        "    return output"
      ],
      "metadata": {
        "id": "7rxVLND11p3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "<font color=green>Q14:</font>\n",
        "<br><font color='green'>\n",
        "Explain the intuition behind this gating mechanism (The same idea was introduced in [Lecture 6](https://hm-ai.github.io/MLF/Lectures/Lecture_6.pdf) ).\n",
        "</font>\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "yX6GVjwm1zZ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "<font color=green>Q15:</font>\n",
        "<br><font color='green'>\n",
        "What is the total number of parameters of the `GatedLinearUnit` layer as a function of $d_i$ and $d_o$ ?\n",
        "</font>\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "a4EP2F0M1RkS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The Gated Residual Network"
      ],
      "metadata": {
        "id": "hElmknMx1gyM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following custom`GatedResidualNetwork` layer is a layer that implements a Gated Residual Network architecture, which is a type of feed-forward neural network that includes gating mechanisms and residual connections. This can be helpful in controlling the flow of information through the network and mitigating problems such as vanishing gradients.\n",
        "\n",
        "\n",
        "\n",
        "* The input tensor $\\xi$ is first passed through the two Dense layers and then through the Dropout layer. The first Dense layer applies an Exponential Linear Unit (ELU) activation function, and the second Dense layer has no activation function specified, meaning it will use a linear activation function by default. The Dropout layer randomly sets a fraction (10% in this case) of the input units to 0 at each update during training, which helps prevent overfitting.\n",
        "\n",
        "* The output from the Dropout layer is passed through the `GatedLinearUnits` (GLU) layer described previously. This layer applies a gating mechanism that can help control the flow of information through the network.\n",
        "\n",
        "* Then, the output from the GLU layer is added to the input tensor. This forms a residual connection, which can help alleviate the vanishing gradient problem and improve the ability of the network to learn complex patterns.\n",
        "\n",
        "* Finally, the `LayerNormalization` layer is applied, which normalizes the output across the features (i.e., the last dimension) rather than across the batch. This can make the model more stable and faster to train.\n",
        "\n",
        "* The following graph summarizes the different steps of processing an input vector $\\xi \\in \\mathbb{R}^{d_i}$ into an output vector $\\tilde{\\xi} \\in \\mathbb{R}^{d_o}$ using the `GatedResidualNetwork`. \n",
        "\n",
        "<center><img width=\"500\" src = \"https://drive.google.com/uc?export=view&id=1Kf0zZgyDvzBxFDqLc0nzOPXwzT4TGABb\"></center>\n"
      ],
      "metadata": {
        "id": "Ueu2RZCW7Jzn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GatedResidualNetwork(tf.keras.layers.Layer):\n",
        "  def __init__(self, hidden_dim, output_dim, **kwargs):\n",
        "    super(GatedResidualNetwork, self).__init__(**kwargs)\n",
        "    self.hidden_dim=hidden_dim\n",
        "    self.output_dim=output_dim\n",
        "    # Define the layers\n",
        "    self.projection = Dense(output_dim)\n",
        "    self.dense_1 = Dense(hidden_dim, activation=\"elu\")\n",
        "    self.dense_2 = Dense(hidden_dim)\n",
        "    self.dropout = Dropout(rate=0.1)\n",
        "    self.glu = GatedLinearUnits(output_dim)\n",
        "    self.layer_norm = LayerNormalization()\n",
        "\n",
        "  def call(self, x):\n",
        "    \"\"\"\n",
        "    x (batch_size, input_dim) -> output (batch_size, output_dim)\n",
        "    \"\"\"\n",
        "    input_dim = x.shape[-1]\n",
        "    z = self.dense_1(x) # (batch_size, hidden_dim)\n",
        "    z = self.dense_2(z) # (batch_size, hidden_dim)\n",
        "    z = self.dropout(z) # (batch_size, hidden_dim)\n",
        "    z = self.glu(z) # (batch_size, output_dim)\n",
        "    if input_dim != self.output_dim:\n",
        "      x = self.projection(x)\n",
        "    output = self.layer_norm(x + z) # (batch_size, output_dim)\n",
        "    return output"
      ],
      "metadata": {
        "id": "KdJH2dOKSXME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Getting the final output vector"
      ],
      "metadata": {
        "id": "HoyNde0dLpZF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We would like to apply a Gated Residual Network (GRN) to each of the embedded features $\\left[\\xi_i^1, \\dots, \\xi_i^d , \\dots, \\xi_i^{D_n} , \\xi_i^{D_n +1}, \\dots, \\xi_i^{d'}, \\dots, \\xi_i^{D_n + D_c} \\right] \\in \\mathbb{R}^{D_e \\times (D_n + D_c)}$ in order to get the following sequence of $D_o$-Dimensional vectors: $\\left[\\tilde{\\xi}_i^1, \\dots, \\tilde{\\xi}_i^d, \\dots, \\tilde{\\xi}_i^{D_n}, \\tilde{\\xi}_i^{D_n +1}, \\dots, \\tilde{\\xi}_i^{d'}, \\dots, \\tilde{\\xi}_i^{D_n + D_c} \\right] \\in \\mathbb{R}^{D_o \\times (D_n + D_c)}$ as shown in the following graph: \n",
        "\n",
        "<center><img width=\"700\" src = \"https://drive.google.com/uc?export=view&id=15lm1HCVFM3365iMWsIVA-X0JZ9qm3puL\"></center>"
      ],
      "metadata": {
        "id": "i8aF3cvO9hhQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let $\\xi_i$ be the concatenation of all the vectors $\\left[\\xi_i^1, \\dots, \n",
        "\\xi_i^d , \\dots, \\xi_i^{D_n} , \\xi_i^{D_n +1}, \\dots, \\xi_i^{d'}, \\dots, \\xi_i^{D_n + D_c} \\right]$. "
      ],
      "metadata": {
        "id": "aJiAC30JLxAV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "<font color=green>Q16:</font>\n",
        "<br><font color='green'>\n",
        "What is the dimensionality of $\\xi_i$ ? \n",
        "</font>\n",
        "\n",
        "---\n",
        "\n",
        "<center><img width=\"700\" src = \"https://drive.google.com/uc?export=view&id=1L3hLN_9ljvKBo-NhYNlsRFtz-Jvl7B-P\"></center>\n"
      ],
      "metadata": {
        "id": "T2aI-JIVJ4ca"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wa want to apply a `GatedResidualNetwork` and a `Softmax` activation function on the vector $\\xi_i$ in order to get the vector $\\alpha_i$ of size $D_n + D_c$ as shown in the following figure:\n",
        "\n",
        "<center><img width=\"700\" src = \"https://drive.google.com/uc?export=view&id=1K3Ryx_M0lc9w8LUQdH6T7tuoJLStwVh3\"></center>"
      ],
      "metadata": {
        "id": "e9OljENkMmlY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "<font color=green>Q17:</font>\n",
        "<br><font color='green'>\n",
        "Let $\\psi_i$ be the output vector of the `GatedResidualNetwork` applied on $\\xi_i$. How can we get $\\alpha_i$ from $\\psi_i$ ?\n",
        "\n",
        "</font>\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "cFCaLK1NNoPr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The final vector is $\\tilde{\\xi}_i = \\sum\\limits_{d=1}^{D_n + D_c} \\alpha_i^d \\tilde{\\xi}_i^{d}$ as shown in the following figure: \n",
        "\n",
        "<center><img width=\"1000\" src = \"https://drive.google.com/uc?export=view&id=1vYuM7IHblWHGXgblVzLRvOqHF24q923p\"></center>"
      ],
      "metadata": {
        "id": "VFfileR4OIk0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "<font color=green>Q18:</font>\n",
        "<br><font color='green'>\n",
        "What is the interpretation of $\\alpha_i^d$ for all $d \\in \\{1, \\dots, D_n + D_c \\}$ ?\n",
        "\n",
        "</font>\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "3Z_-BOMpO6ok"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Final Model"
      ],
      "metadata": {
        "id": "6GZJZCh6SXME"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Coding the Final Model"
      ],
      "metadata": {
        "id": "cbhe1XJvRF6D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following graph summarizes the whole Forward Propagation. \n",
        "\n",
        "The whole process is coded in the `FinalModel` model below. \n",
        "\n",
        "It takes as input the tensors $\\begin{bmatrix}\n",
        "x_i^1 \\\\\n",
        "\\vdots\\\\\n",
        "x_i^{D_n}\\\\\n",
        "\\end{bmatrix}$ and $\\begin{bmatrix}\n",
        "x_i^{D_n+1} \\\\\n",
        "\\vdots\\\\\n",
        "x_i^{D_n + D_c}\\\\\n",
        "\\end{bmatrix}$ and outputs the prediction tensor $\\tilde{\\xi}_i \\in \\mathbb{R}^{D_o}$ and the alpha coeffecitions  $\\alpha_i \\in \\mathbb{R}^{D_n + D_c}$ "
      ],
      "metadata": {
        "id": "rlz1rcYAQ664"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><img width=\"1000\" src = \"https://drive.google.com/uc?export=view&id=1vYuM7IHblWHGXgblVzLRvOqHF24q923p\"></center>"
      ],
      "metadata": {
        "id": "MMM08EmGSXME"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class VariableSelectionNetwork(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_features, hidden_dim, output_dim, **kwargs):\n",
        "        super(VariableSelectionNetwork, self).__init__(**kwargs)\n",
        "        self.num_features = num_features\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.output_dim = output_dim\n",
        "        # Layers\n",
        "        self.list_grns = [GatedResidualNetwork(hidden_dim=hidden_dim,\n",
        "                                               output_dim=output_dim) for _ in range(num_features)]\n",
        "        self.flatten_grn = GatedResidualNetwork(hidden_dim=hidden_dim,\n",
        "                                                output_dim=num_features)\n",
        "\n",
        "    def call(self, stack_features):\n",
        "        \"\"\"\n",
        "        stack_features (batch_size, embedding_dim, num_features) -> outputs (batch_size, output_dim), feature_weights (batch_size, num_features)\n",
        "        \"\"\"\n",
        "        # Apply the gated residual network to each feature vector\n",
        "        list_features = []\n",
        "        for i, grn in enumerate(self.list_grns):\n",
        "            feature = grn(stack_features[:, :, i])\n",
        "            list_features.append(feature)\n",
        "        # [(batch_size, output_dim), ..., (batch_size, output_dim)] of size num_features -> (batch_size, output_dim, num_features)\n",
        "        stacked_features = tf.stack(list_features, axis=-1)  # (batch_size, output_dim, num_features)\n",
        "        # Reshape stacked_features (batch_size, output_dim, num_features) -> (batch_size, output_dim*num_features)\n",
        "        batch_size = tf.shape(stacked_features)[0]\n",
        "        stack_features_reshaped = tf.reshape(stacked_features, shape=(batch_size, stacked_features.shape[1] * stacked_features.shape[2]))\n",
        "        # Apply GRN (batch_size, output_dim*num_features) -> (batch_size, num_features)\n",
        "        stack_features_reshaped = self.flatten_grn(stack_features_reshaped)\n",
        "        # Apply Softmax (batch_size, num_features) -> (batch_size, num_features)\n",
        "        weights = tf.nn.softmax(stack_features_reshaped, axis=-1)\n",
        "        # Reshape weigths(batch_size, num_features) -> (batch_size, 1, num_features)\n",
        "        weights_reshaped = weights[:, tf.newaxis, :]\n",
        "        # Multiply weights and stacked_features (batch_size, output_dim, num_features), (batch_size, 1, num_features) -> (batch_size, output_dim, num_features)\n",
        "        output = tf.multiply(stacked_features, weights_reshaped)\n",
        "        # Sum over the num_features axis (batch_size, output_dim, num_features) -> (batch_size, output_dim)\n",
        "        output = tf.reduce_sum(output, axis=-1)\n",
        "        return output, weights\n",
        "\n",
        "class FinalModel(tf.keras.models.Model):\n",
        "    def __init__(self, embedding_dim, num_numerical, num_categorical, cardinalities, hidden_dim, output_dim, **kwargs):\n",
        "        super(FinalModel, self).__init__(**kwargs)\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.num_numerical = num_numerical\n",
        "        self.num_categorical = num_categorical\n",
        "        self.cardinalities = cardinalities\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.output_dim = output_dim\n",
        "        # Layers\n",
        "        self.input_transformation = InputTransformation(embedding_dim=embedding_dim,\n",
        "                                                        num_numerical=num_numerical,\n",
        "                                                        num_categorical=num_categorical,\n",
        "                                                        cardinalities=cardinalities)\n",
        "        self.vsn = VariableSelectionNetwork(num_features=num_numerical + num_categorical,\n",
        "                                            hidden_dim=hidden_dim,\n",
        "                                            output_dim=output_dim)\n",
        "        self.dense = Dense(1, activation=\"sigmoid\")\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x_num, x_cat = inputs\n",
        "        stack_features = self.input_transformation(x_num, x_cat)\n",
        "        output, alpha = self.vsn(stack_features)\n",
        "        output = self.dense(output)\n",
        "        return tf.squeeze(output), alpha\n"
      ],
      "metadata": {
        "id": "eswmvY2HUg2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "<font color=green>Q19:</font>\n",
        "<br><font color='green'>\n",
        "Create a summary of the entire `FinalModel` by specifying the following elements: The different layers used, with a brief description of each layer and how the shape of the data changes after each layer transformation.\n",
        "\n",
        "</font>\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "SS1aGmdlRL8t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The Forward Propagation"
      ],
      "metadata": {
        "id": "XpRI3XiRXtVG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us apply the `FinalModel` on `(X_num_train, X_cat_train)`."
      ],
      "metadata": {
        "id": "PZUlXn6NX8lk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following table summarizes the different hyperparameters of the `FinalModel`:\n",
        "\n",
        "| Attribute | Description |\n",
        "|-----------|-------------|\n",
        "| `embedding_dim` | The dimension of the embedding space for both numerical and categorical variables. |\n",
        "| `num_numerical` | The number of numerical features  |\n",
        "| `num_categorical` | The number of categorical features |\n",
        "| `cardinalities` | A list of integers specifying the number of distinct categories for each categorical feature. |\n",
        "| `hidden_dim` | The dimensionality of the hidden layers in the Gated Residual Networks (GRN) |\n",
        "| `output_dim` | The dimensionality of the output space of the GRNs |\n"
      ],
      "metadata": {
        "id": "SJYwOLDZYkVV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "<font color=green>Q20:</font>\n",
        "<br><font color='green'>\n",
        "Complete the following code to create an instance of `FinalModel` and apply it to `(X_num_train, X_cat_train)`\n",
        "\n",
        "</font>\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "LoHr7DEYZNGQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of the model\n",
        "fm = FinalModel(embedding_dim=### YOUR CODE HERE ###,\n",
        "                num_numerical=### YOUR CODE HERE ###,\n",
        "                num_categorical=### YOUR CODE HERE ###,\n",
        "                cardinalities=### YOUR CODE HERE ###,\n",
        "                hidden_dim=### YOUR CODE HERE ###,\n",
        "                output_dim=### YOUR CODE HERE ###)\n",
        "\n",
        "# Apply the model to the tensors x_num, x_cat\n",
        "output, alpha = fm((X_num_train, X_cat_train))\n",
        "\n",
        "# Print the shape of the output tensor \n",
        "### YOUR CODE HERE ###\n",
        "\n",
        "# Print the shape of the alpha tensor \n",
        "### YOUR CODE HERE ###"
      ],
      "metadata": {
        "id": "ZnNjkL12SXMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "<font color=green>Q21:</font>\n",
        "<br><font color='green'>\n",
        "Explain why $\\frac{1}{N_T} \\sum\\limits_{i=1}^{N_T} \\sum\\limits_{d=1}^{D_n+D_c} \\alpha_i^d = 1$ and make sure your `alpha` tensor verifies the aforementioned equation.\n",
        "\n",
        "</font>\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "1Y0kiBPFZ0l2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the Model"
      ],
      "metadata": {
        "id": "kmNIAQZZbstb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Preparing the code"
      ],
      "metadata": {
        "id": "3xtl5FGVck7s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code is provided to you, no need to change it. "
      ],
      "metadata": {
        "id": "ShApwZV6ydcy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Create the training dataset\n",
        "def create_dataset(X_num, X_cat, y, batch_size=32):\n",
        "    X_num = tf.data.Dataset.from_tensor_slices(X_num.astype('float32'))\n",
        "    X_cat = tf.data.Dataset.from_tensor_slices(X_cat.astype('int32'))\n",
        "    y = tf.data.Dataset.from_tensor_slices(y.astype('float32'))\n",
        "    dataset = tf.data.Dataset.zip(((X_num, X_cat), y)).batch(batch_size)\n",
        "    return dataset\n",
        "\n",
        "\n",
        "## Training Process\n",
        "@tf.function\n",
        "def grad_fn(model, inputs, targets, loss_fn):\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions, _ = model(inputs)  \n",
        "        loss_value = loss_fn(targets, predictions)\n",
        "    grads = tape.gradient(loss_value, model.trainable_variables)\n",
        "    return loss_value, grads, predictions\n",
        "\n",
        "def f1_score(precision, recall):\n",
        "    return 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "\n",
        "## Train the model\n",
        "\n",
        "def train_model(model, num_epochs, train_dataset, test_dataset, optimizer, loss, grad_fn):\n",
        "    mean_train_loss = []\n",
        "    mean_train_auc = []\n",
        "    mean_train_f1 = []\n",
        "    mean_train_recall = []\n",
        "    mean_train_precision = []\n",
        "\n",
        "    mean_test_loss = []\n",
        "    mean_test_auc = []\n",
        "    mean_test_f1 = []\n",
        "    mean_test_recall = []\n",
        "    mean_test_precision = []\n",
        "\n",
        "    for e in range(num_epochs):\n",
        "        train_loss_tmp = []\n",
        "        train_auc_tmp = []\n",
        "        train_f1_tmp = []\n",
        "        train_recall_tmp = []\n",
        "        train_precision_tmp = []\n",
        "\n",
        "        print(f\"Epoch - {e}\")\n",
        "        for inputs, outputs in train_dataset:\n",
        "            g_loss, grads, y_pred = grad_fn(model, inputs, outputs, loss)\n",
        "\n",
        "            # Update metrics\n",
        "            auc = AUC()\n",
        "            precision = Precision()\n",
        "            recall = Recall()\n",
        "\n",
        "            auc.update_state(outputs, y_pred)\n",
        "            precision.update_state(outputs, y_pred)\n",
        "            recall.update_state(outputs, y_pred)\n",
        "\n",
        "            auc_result = auc.result().numpy()\n",
        "            precision_result = precision.result().numpy()\n",
        "            recall_result = recall.result().numpy()\n",
        "            f1_result = f1_score(precision_result, recall_result)\n",
        "\n",
        "            train_loss_tmp.append(g_loss)\n",
        "            train_auc_tmp.append(auc_result)\n",
        "            train_f1_tmp.append(f1_result)\n",
        "            train_recall_tmp.append(recall_result)\n",
        "            train_precision_tmp.append(precision_result)\n",
        "\n",
        "            print(f\"Train Loss - {g_loss};\\t Train AUC - {auc_result};\\t Train F1 Score - {f1_result};\\t Train Recall - {recall_result};\\t Train Precision - {precision_result}\")\n",
        "\n",
        "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "        mean_train_loss.append(np.mean(train_loss_tmp))\n",
        "        mean_train_auc.append(np.mean(train_auc_tmp))\n",
        "        mean_train_f1.append(np.mean(train_f1_tmp))\n",
        "        mean_train_recall.append(np.mean(train_recall_tmp))\n",
        "        mean_train_precision.append(np.mean(train_precision_tmp))\n",
        "\n",
        "        # Evaluate on test data\n",
        "        test_loss_tmp = []\n",
        "        test_auc_tmp = []\n",
        "        test_f1_tmp = []\n",
        "        test_recall_tmp = []\n",
        "        test_precision_tmp = []\n",
        "\n",
        "        for inputs, outputs in test_dataset:\n",
        "            y_pred, _ = model(inputs)\n",
        "            test_loss_value = loss(outputs, y_pred)\n",
        "\n",
        "            # Update metrics\n",
        "            auc = AUC()\n",
        "            precision = Precision()\n",
        "            recall = Recall()\n",
        "\n",
        "            auc.update_state(outputs, y_pred)\n",
        "            precision.update_state(outputs, y_pred)\n",
        "            recall.update_state(outputs, y_pred)\n",
        "\n",
        "            auc_result = auc.result().numpy()\n",
        "            precision_result = precision.result().numpy()\n",
        "            recall_result = recall.result().numpy()\n",
        "            f1_result = f1_score(precision_result, recall_result)\n",
        "\n",
        "            test_loss_tmp.append(test_loss_value)\n",
        "            test_auc_tmp.append(auc_result)\n",
        "            test_f1_tmp.append(f1_result)\n",
        "            test_recall_tmp.append(recall_result)\n",
        "            test_precision_tmp.append(precision_result)\n",
        "\n",
        "            print(f\"Test Loss - {test_loss_value};\\t Test AUC - {auc_result};\\t Test F1 Score - {f1_result};\\t Test Recall - {recall_result};\\t Test Precision - {precision_result}\")\n",
        "\n",
        "        mean_test_loss.append(np.mean(test_loss_tmp))\n",
        "        mean_test_auc.append(np.mean(test_auc_tmp))\n",
        "        mean_test_f1.append(np.mean(test_f1_tmp))\n",
        "        mean_test_recall.append(np.mean(test_recall_tmp))\n",
        "        mean_test_precision.append(np.mean(test_precision_tmp))\n",
        "\n",
        "    return mean_train_loss, mean_train_auc, mean_train_f1, mean_train_recall, mean_train_precision, mean_test_loss, mean_test_auc, mean_test_f1, mean_test_recall, mean_test_precision"
      ],
      "metadata": {
        "id": "SGAb0YMLcyFn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Preparing the Hyperparameters"
      ],
      "metadata": {
        "id": "VdwSUfSnbupF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "<font color=green>Q22:</font>\n",
        "<br><font color='green'>\n",
        "Justify your choice of each of these hyperparameters\n",
        "\n",
        "</font>\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "KcRh2hd3cG8G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_numerical = ### YOUR CODE HERE ###\n",
        "num_categorical = ### YOUR CODE HERE ###\n",
        "cardinalities = ### YOUR CODE HERE ###\n",
        "embedding_dim = ### YOUR CODE HERE ###\n",
        "hidden_dim = ### YOUR CODE HERE ###\n",
        "output_dim= ### YOUR CODE HERE ###\n",
        "epochs = ### YOUR CODE HERE ###\n",
        "batch_size = ### YOUR CODE HERE ###\n",
        "num_epochs = ### YOUR CODE HERE ###\n",
        "learning_rate = ### YOUR CODE HERE ###"
      ],
      "metadata": {
        "id": "Ld2S51KPZz1t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create and instance `fm` of the `FinalModel`"
      ],
      "metadata": {
        "id": "RBC7I9qey07Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of the model\n",
        "fm = FinalModel(embedding_dim=embedding_dim,\n",
        "                num_numerical=num_numerical,\n",
        "                num_categorical=num_categorical,\n",
        "                cardinalities=cardinalities,\n",
        "                hidden_dim=hidden_dim,\n",
        "                output_dim=output_dim)\n",
        "\n",
        "# Defining the Optimizer\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
        "\n",
        "# Defining the Loss function\n",
        "loss = tf.keras.losses.binary_crossentropy"
      ],
      "metadata": {
        "id": "m75g5HpKeTZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make sure the following tensors in this table are well defined and run the next cell to create `train_dataset`and `test_dataset`\n",
        "\n",
        "| Description of the Tensor                                                                                                       | Name        | Shape        |\n",
        "|---------------------------------------------------------------------------------------------------------------------------------|-------------|--------------|\n",
        "| The tensor containing all the numerical features associated with the training dataset                                           | X_num_train | $(N_T, D_n)$ |\n",
        "| The tensor containing all the label encoded categorical features associated with the training dataset                           | X_cat_train | $(N_T, D_c)$ |\n",
        "| The tensor containing all the features (numerical and label encoded categorical features) associated with the training dataset  | X_train     | $(N_T, D)$   |\n",
        "| The tensor containing all the numerical features associated with the test dataset                                               | X_num_test  | $(N_t, D_n)$ |\n",
        "| The tensor containing all the label encoded categorical features associated with the test dataset                               | X_cat_test  | $(N_t, D_c)$ |\n",
        "| The tensor containing all the features (numerical and label encoded categorical features) associated with the test dataset      | X_test      | $(N_t, D)$   |\n",
        "| The training target tensor                                                                                                      | y_train     | $(N_T,)$   |\n",
        "| The test target tensor                                                                                                          | y_test      | $(N_t,)$   |"
      ],
      "metadata": {
        "id": "HAsTz33afUCo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = create_dataset(X_num_train, X_cat_train, y_train, batch_size=batch_size)\n",
        "test_dataset = create_dataset(X_num_test, X_cat_test, y_test, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "xUuB3ggWcnDX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The Training Process"
      ],
      "metadata": {
        "id": "q66X-qjCf7bO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mean_train_loss, mean_train_auc, mean_train_f1, mean_train_recall, mean_train_precision, mean_test_loss, mean_test_auc, mean_test_f1, mean_test_recall, mean_test_precision = train_model(fm, num_epochs, train_dataset, test_dataset, optimizer, loss, grad_fn)\n"
      ],
      "metadata": {
        "id": "ToyLdl-IcUNT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The method `train_model` trains the `fm` model and outputs the following lists:"
      ],
      "metadata": {
        "id": "cPqYQq8VmaOz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Element               | Description                                                                 |\n",
        "|-----------------------|-----------------------------------------------------------------------------|\n",
        "| mean_train_loss       | This is the average training loss per epoch.                                |\n",
        "| mean_train_auc        | This is the average Area Under the ROC Curve (AUC) for the training set.    |\n",
        "| mean_train_f1         | This is the average F1 score for the training set.                          |\n",
        "| mean_train_recall     | This is the average recall score for the training set.                      |\n",
        "| mean_train_precision  | This is the average precision score for the training set.                   |\n",
        "| mean_test_loss        | This is the average loss on the test set per epoch.                         |\n",
        "| mean_test_auc         | This is the average Area Under the ROC Curve (AUC) for the test set.        |\n",
        "| mean_test_f1          | This is the average F1 score for the test set.                              |\n",
        "| mean_test_recall      | This is the average recall score for the test set.                          |\n",
        "| mean_test_precision   | This is the average precision score for the test set.                       |\n"
      ],
      "metadata": {
        "id": "Og0zPzVIhcdr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "<font color=green>Q23:</font>\n",
        "<br><font color='green'>\n",
        "Using the data provided in the variables `mean_train_loss`, `mean_train_auc`, `mean_train_f1`, `mean_train_recall`, `mean_train_precision`, `mean_test_loss`, `mean_test_auc`, `mean_test_f1`, `mean_test_recall`, and `mean_test_precision`, create the following plots:\n",
        "  * A plot showing the training and testing loss over each epoch. The x-axis should represent the epoch number and the y-axis should represent the loss. \n",
        "\n",
        "  * A plot showing the training and testing AUC over each epoch. The x-axis should represent the epoch number and the y-axis should represent the AUC. \n",
        "\n",
        "  * A plot showing the training and testing F1 score over each epoch. The x-axis should represent the epoch number and the y-axis should represent the F1 score.\n",
        "\n",
        "  * A plot showing the training and testing recall over each epoch. The x-axis should represent the epoch number and the y-axis should represent the recall. \n",
        "\n",
        "  * A plot showing the training and testing precision over each epoch. The x-axis should represent the epoch number and the y-axis should represent the precision. \n",
        "\n",
        "For each plot, include a legend to distinguish between the training and testing data.\n",
        "\n",
        "Discuss any trends or patterns you observe in these plots and what they may indicate about the performance and generalization of your model.\n",
        "\n",
        "</font>\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "6cS2ErYyh5_R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Importance"
      ],
      "metadata": {
        "id": "lqvO9pdnkJy3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the trained model `fm` and the feature data `X_num_train`, `X_cat_train`, `X_num_test` and `X_cat_test`, We would like to create a bar plot visualizing the feature importance for both training and testing data. "
      ],
      "metadata": {
        "id": "uiuT6DSPk_IS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "<font color=green>Q24:</font>\n",
        "<br><font color='green'>\n",
        "Make predictions using the model `fm` on both the training and testing data. The model returns two outputs: the predicted values and the importance weights (alpha) for each feature.\n",
        "\n",
        "</font>\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2DCU4Gl5kmwP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "<font color=green>Q25:</font>\n",
        "<br><font color='green'>\n",
        "Compute the mean feature importance for both training and testing data by averaging the importance weight associated with each feature (numerical or categorical).\n",
        "\n",
        "</font>\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "_jR_n9--mDpA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "<font color=green>Q26:</font>\n",
        "<br><font color='green'>\n",
        "Create a horizontal bar plot showing the feature importance of each feature for both the training and testing data. Use different colors to distinguish between the training and testing data. The y-axis should represent the features. The x-axis should represent the feature importance. Include a legend to distinguish between the training and testing data.\n",
        "\n",
        "</font>\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "7bGjn6gCmG88"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your final plot should allow for a clear comparison of feature importance between the training and testing data, as shown in the following graph: \n",
        "\n",
        "<center><img width=\"1000\" src = \"https://drive.google.com/uc?export=view&id=1zxsLTZgCQcxiqfEBH-rgcWu3JCpCMT01\"></center>\n",
        "\n",
        "\n",
        "---\n",
        "<font color=green>Q27:</font>\n",
        "<br><font color='green'>\n",
        "After generating the plot, provide a brief discussion of what the plot reveals about the model's use of the features for prediction, and if the model treats the features similarly or differently between the training and testing data.\n",
        "\n",
        "</font>\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "6V9CGA_BmQm_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using the `FinalModel` for a sequential problem"
      ],
      "metadata": {
        "id": "JVMTSOpUmxuh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The code is not required for this question**"
      ],
      "metadata": {
        "id": "myOVkg94ocqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "<font color=green>Q28:</font>\n",
        "<br><font color='green'>\n",
        "Given a time series forecasting task, where your objective is to predict an asset's future direction (either upwards or downwards) $T_y$ steps ahead using $T_x$ previous feature vectors, how would you adjust the `FinalModel` to accommodate this? Each feature vector encompasses both numerical and categorical variables at each time step. The `FinalModel`, as we have discussed before, is a non-sequential model and doesn't account for the temporal relationships between time steps. Elaborate in detail how you would modify the `FinalModel` to handle this time-dependent problem.\n",
        "\n",
        "</font>\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "JMz53NBtoG7W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best of luck !  "
      ],
      "metadata": {
        "id": "ALFMcUVq0yTW"
      }
    }
  ]
}